{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sep=[ '|',',', ';']\n",
    "for i in sep:\n",
    "    dec=','\n",
    "    if i==',':\n",
    "        dec='.'\n",
    "    df=pd.read_csv(\"proj2_data.csv\", sep=i, decimal=dec)\n",
    "    if len(list(df.columns))>1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           full_name     field   language code  task_1  task_2  task_3  \\\n0   Rowan Harrington    drones     python  wej     3.1     2.0     4.4   \n1         Nash Wyatt    racing       java  sfe     4.2     2.0     2.0   \n2     Jadiel Ramirez     media  cplusplus  vaw     4.0     4.9     3.0   \n3     Makaila Atkins    racing      swift  ugt     4.1     5.0     4.8   \n4     Melanie Fuller    racing     python  owb     2.7     2.0     2.0   \n5      Layla Woodard    drones     python  wuf     2.8     2.0     2.0   \n6         Edwin Hale     media      swift  ceq     4.9     3.0     3.4   \n7       Travis Rocha  robotics  cplusplus  eir     5.0     4.9     5.0   \n8       Ricky Howell     media       java  vos     2.1     2.0     2.0   \n9    Addyson Brennan    drones       java  cov     4.4     3.7     4.0   \n10      Megan Barker    drones      swift  oqq     3.9     4.0     4.4   \n11    Abel Hendricks    racing     python  dfa     4.1     5.0     5.0   \n\n    tasks_avg    task_grade jury_score     final_grade  \n0    3.166667   dostateczny    3,5 pts     dostateczny  \n1    2.733333  bardzo dobry        5 p          mierny  \n2    3.966667         dobry        3.5          mierny  \n3    4.633333         dobry          2     dostateczny  \n4    2.233333  bardzo dobry      pts 2          mierny  \n5    2.266667  bardzo dobry       3,5p     dostateczny  \n6    3.766667   dostateczny   -1 (dnf)  niedostateczny  \n7    4.966667   dostateczny          0  niedostateczny  \n8    2.033333         dobry    waiting  niedostateczny  \n9    4.033333  bardzo dobry          -  niedostateczny  \n10   4.100000   dostateczny          2     dostateczny  \n11   4.700000  bardzo dobry          4          mierny  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_name</th>\n      <th>field</th>\n      <th>language</th>\n      <th>code</th>\n      <th>task_1</th>\n      <th>task_2</th>\n      <th>task_3</th>\n      <th>tasks_avg</th>\n      <th>task_grade</th>\n      <th>jury_score</th>\n      <th>final_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rowan Harrington</td>\n      <td>drones</td>\n      <td>python</td>\n      <td>wej</td>\n      <td>3.1</td>\n      <td>2.0</td>\n      <td>4.4</td>\n      <td>3.166667</td>\n      <td>dostateczny</td>\n      <td>3,5 pts</td>\n      <td>dostateczny</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nash Wyatt</td>\n      <td>racing</td>\n      <td>java</td>\n      <td>sfe</td>\n      <td>4.2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.733333</td>\n      <td>bardzo dobry</td>\n      <td>5 p</td>\n      <td>mierny</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jadiel Ramirez</td>\n      <td>media</td>\n      <td>cplusplus</td>\n      <td>vaw</td>\n      <td>4.0</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>3.966667</td>\n      <td>dobry</td>\n      <td>3.5</td>\n      <td>mierny</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Makaila Atkins</td>\n      <td>racing</td>\n      <td>swift</td>\n      <td>ugt</td>\n      <td>4.1</td>\n      <td>5.0</td>\n      <td>4.8</td>\n      <td>4.633333</td>\n      <td>dobry</td>\n      <td>2</td>\n      <td>dostateczny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Melanie Fuller</td>\n      <td>racing</td>\n      <td>python</td>\n      <td>owb</td>\n      <td>2.7</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.233333</td>\n      <td>bardzo dobry</td>\n      <td>pts 2</td>\n      <td>mierny</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Layla Woodard</td>\n      <td>drones</td>\n      <td>python</td>\n      <td>wuf</td>\n      <td>2.8</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.266667</td>\n      <td>bardzo dobry</td>\n      <td>3,5p</td>\n      <td>dostateczny</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Edwin Hale</td>\n      <td>media</td>\n      <td>swift</td>\n      <td>ceq</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>3.766667</td>\n      <td>dostateczny</td>\n      <td>-1 (dnf)</td>\n      <td>niedostateczny</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Travis Rocha</td>\n      <td>robotics</td>\n      <td>cplusplus</td>\n      <td>eir</td>\n      <td>5.0</td>\n      <td>4.9</td>\n      <td>5.0</td>\n      <td>4.966667</td>\n      <td>dostateczny</td>\n      <td>0</td>\n      <td>niedostateczny</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ricky Howell</td>\n      <td>media</td>\n      <td>java</td>\n      <td>vos</td>\n      <td>2.1</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.033333</td>\n      <td>dobry</td>\n      <td>waiting</td>\n      <td>niedostateczny</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Addyson Brennan</td>\n      <td>drones</td>\n      <td>java</td>\n      <td>cov</td>\n      <td>4.4</td>\n      <td>3.7</td>\n      <td>4.0</td>\n      <td>4.033333</td>\n      <td>bardzo dobry</td>\n      <td>-</td>\n      <td>niedostateczny</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Megan Barker</td>\n      <td>drones</td>\n      <td>swift</td>\n      <td>oqq</td>\n      <td>3.9</td>\n      <td>4.0</td>\n      <td>4.4</td>\n      <td>4.100000</td>\n      <td>dostateczny</td>\n      <td>2</td>\n      <td>dostateczny</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Abel Hendricks</td>\n      <td>racing</td>\n      <td>python</td>\n      <td>dfa</td>\n      <td>4.1</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>4.700000</td>\n      <td>bardzo dobry</td>\n      <td>4</td>\n      <td>mierny</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open (\"proj2_ex01.pkl\", \"wb\") as f:\n",
    "    pkl.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict={}\n",
    "f=open(\"proj2_scale.txt\", 'r')\n",
    "t=1\n",
    "for i in f:\n",
    "    dict.update({i.replace('\\n', ''):t})\n",
    "    t+=1\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2[[\"task_grade\", \"final_grade\"]]=df2[[\"task_grade\", \"final_grade\"]].replace(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"proj2_ex02.pkl\", \"wb\") as f:\n",
    "    pkl.dump(df2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "full_name        object\nfield            object\nlanguage         object\ncode             object\ntask_1          float64\ntask_2          float64\ntask_3          float64\ntasks_avg       float64\ntask_grade     category\njury_score       object\nfinal_grade    category\ndtype: object"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################################################\n",
    "\n",
    "f=open(\"proj2_scale.txt\", 'r')\n",
    "\n",
    "category=pd.CategoricalDtype([i.replace(\"\\n\", '') for i in f])\n",
    "df3=df.copy()\n",
    "df3[[\"task_grade\", \"final_grade\"]]=df3[[\"task_grade\", \"final_grade\"]].astype(category)\n",
    "\n",
    "f.close()\n",
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"proj2_ex03.pkl\", \"wb\") as f:\n",
    "    pkl.dump(df3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "df4=pd.DataFrame()\n",
    "for i in df.keys():\n",
    "    if df[i].dtype==object:\n",
    "        d=df[i].str.extract(\"([-+]?\\d*[\\.\\,]?\\d+)\")\n",
    "        if not d.isna().values.all():\n",
    "            df4[i]=d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df4=df4[\"jury_score\"].str.replace(',', '.')\n",
    "pd.to_numeric(df4)\n",
    "df4=df4.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "0      -1\n1       0\n2       2\n3       2\n4       2\n5     3.5\n6     3.5\n7     3.5\n8       4\n9       5\n10    NaN\n11    NaN\nName: jury_score, dtype: object"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"proj2_ex04.pkl\", \"wb\") as f:\n",
    "    pkl.dump(df4, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text=df.columns[df.dtypes==object]\n",
    "\n",
    "uniquecols=df.columns[df.nunique()<=10]\n",
    "\n",
    "atoz=df.columns[df.columns.str.fullmatch(\"[a-z]+\")]\n",
    "\n",
    "notin2=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
